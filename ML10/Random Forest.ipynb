{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, \\\n",
    "                             AdaBoostClassifier, GradientBoostingRegressor, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_moons\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble models\n",
    "### Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.88\n",
      "SVC 0.888\n",
      "VotingClassifier 0.904\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "X, y = make_moons(n_samples=500, noise=0.30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "log_cl = LogisticRegression()\n",
    "rf_cl = RandomForestClassifier()\n",
    "svm_cl = SVC()\n",
    "\n",
    "voting_cl = VotingClassifier([('lg',log_cl),('rf', rf_cl),('svc', svm_cl)], voting='hard')\n",
    "\n",
    "for model in [log_cl, rf_cl, svm_cl, voting_cl]:\n",
    "    model.fit(X_train, y_train)\n",
    "    print(model.__class__.__name__,accuracy_score(y_pred=model.predict(X_test), y_true=y_test))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Voting (Using Probabilities instead of hard decisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.88\n",
      "SVC 0.888\n",
      "VotingClassifier 0.92\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "X, y = make_moons(n_samples=500, noise=0.30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "log_cl = LogisticRegression()\n",
    "rf_cl = RandomForestClassifier()\n",
    "svm_cl = SVC(probability=True)\n",
    "\n",
    "voting_cl = VotingClassifier([('lg',log_cl),('rf', rf_cl),('svc', svm_cl)], voting='soft')\n",
    "\n",
    "for model in [log_cl, rf_cl, svm_cl, voting_cl]:\n",
    "    model.fit(X_train, y_train)\n",
    "    print(model.__class__.__name__,accuracy_score(y_pred=model.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging and Pasting (Sampling without replacement)\n",
    "### Single Decision Tree trained with all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.872\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train, y_train)\n",
    "print(\"Accuracy Score: {:.3f}\".format(accuracy_score(y_pred=dt_clf.predict(X_test), y_true=y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulating Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of samples which does not contain a number 0.37\n"
     ]
    }
   ],
   "source": [
    "data = range(10000)\n",
    "result = []\n",
    "for i in range(500):\n",
    "    result.append(set(np.random.choice(data, 10000, replace=True)))\n",
    "\n",
    "count =[]\n",
    "for i in range(10000):\n",
    "    acum = 0\n",
    "    for j in range(500):\n",
    "        if i in result[j]:\n",
    "            acum +=1\n",
    "    count.append(acum/500)   \n",
    "print(\"Ratio of samples which does not contain a number {:.2f}\".format(1 - np.mean(count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Score estimation 0.9253333333333333\n",
      "Accuracy Score: 0.912\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500, max_samples=100, bootstrap=True, n_jobs=-1, oob_score=True\n",
    ")\n",
    "bag_clf.fit(X_train, y_train)\n",
    "print(\"OOB Score estimation {}\".format(bag_clf.oob_score_))\n",
    "print(\"Accuracy Score: {:.3f}\".format(accuracy_score(y_pred=bag_clf.predict(X_test), y_true=y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.904\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500, max_samples=100, bootstrap=False, n_jobs=-1\n",
    ")\n",
    "bag_clf.fit(X_train, y_train)\n",
    "print(\"Accuracy Score: {:.3f}\".format(accuracy_score(y_pred=bag_clf.predict(X_test), y_true=y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Score estimation 0.745\n",
      "Accuracy Score: 0.713\n",
      "OOB Score estimation 0.814\n",
      "Accuracy Score: 0.807\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier( max_leaf_nodes=16, splitter='random'),\n",
    "    n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1, oob_score=True\n",
    ")\n",
    "bag_clf.fit(X_train, y_train)\n",
    "print(\"OOB Score estimation {:.3f}\".format(bag_clf.oob_score_))\n",
    "print(\"Accuracy Score: {:.3f}\".format(accuracy_score(y_pred=bag_clf.predict(X_test), y_true=y_test)))\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1, oob_score=True)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "print(\"OOB Score estimation {:.3f}\".format(rf_clf.oob_score_))\n",
    "print(\"Accuracy Score: {:.3f}\".format(accuracy_score(y_pred=rf_clf.predict(X_test), y_true=y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.896\n"
     ]
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), \n",
    "                            n_estimators=200, algorithm='SAMME.R', learning_rate=0.5)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "print('Accuracy Score {:.3f}'.format(accuracy_score(y_pred=ada_clf.predict(X_test), y_true=y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Predicted MSE:0.013303033484734628\n",
      "GTB Predicted MSE:0.005038058938993283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg1.fit(X, y)\n",
    "\n",
    "y2 = y - tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg2.fit(X, y2)\n",
    "\n",
    "y3 = y2 - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg3.fit(X, y3)\n",
    "\n",
    "X_new = np.array([[0.8]])\n",
    "\n",
    "print('DT Predicted MSE:{}'.format(mean_squared_error(y_pred=tree_reg1.predict(X), y_true=y)))\n",
    "y_pred = sum(tree.predict(X) for tree in (tree_reg1, tree_reg2, tree_reg3))\n",
    "print('GTB Predicted MSE:{}'.format(mean_squared_error(y_pred=y_pred, y_true=y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import pipeline\n",
    "from sklearn.preprocessing import scale, FunctionTransformer, MaxAbsScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST contains 70000 samples of 784 features each\n",
      "Each feature corresponds to a b/w intensity pixel in a picture of 28x28 pixels\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_mldata('MNIST original')\n",
    "print('MNIST contains {} samples of {} features each'.format(mnist.data.shape[0],mnist.data.shape[1]))\n",
    "print('Each feature corresponds to a b/w intensity pixel in a picture of {0}x{0} pixels'.\n",
    "      format(int(math.sqrt(mnist.data.shape[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = shuffle(mnist.data, mnist.target)\n",
    "X_train, X_validation, X_test = X[0:50000], X[50000:60000], X[60000:70000]\n",
    "y_train, y_validation, y_test = y[0:50000], y[50000:60000], y[60000:70000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_validation, X_test = X[0:5000], X[5000:6000], X[6000:7000]\n",
    "y_train, y_validation, y_test = y[0:5000], y[5000:6000], y[6000:7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random accuracy 0.089\n"
     ]
    }
   ],
   "source": [
    "dummy_cl = DummyClassifier()\n",
    "dummy_cl.fit(X_train, y_train)\n",
    "y_pred = dummy_cl.predict(X_validation)\n",
    "print('Random accuracy {}'.format(accuracy_score(y_pred, y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in [1,50,100,150,200, 255]:\n",
    "    svm_cl = SVC()\n",
    "    %time svm_cl.fit(X_train/i, y_train)\n",
    "    y_pred = svm_cl.predict(X_validation/i)\n",
    "    print('SVM accuracy standarised by {}: {}'.format(i, accuracy_score(y_pred, y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy 0.11\n"
     ]
    }
   ],
   "source": [
    "svm_cl = SVC()\n",
    "svm_cl.fit(X_train, y_train)\n",
    "y_pred = svm_cl.predict(X_validation)\n",
    "print('SVM accuracy {}'.format(accuracy_score(y_pred, y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled SVM accuracy 0.92\n"
     ]
    }
   ],
   "source": [
    "transformer = FunctionTransformer(func=lambda x: x/255)\n",
    "svm_pipe = pipeline.Pipeline([('scale',transformer), ('svm', SVC(probability=True))])\n",
    "svm_pipe.fit(X_train, y_train)\n",
    "y_pred = svm_pipe.predict(X_validation)\n",
    "print('Scaled SVM accuracy {}'.format(accuracy_score(y_pred, y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF accuracy 0.902\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_validation)\n",
    "print('RF accuracy {}'.format(accuracy_score(y_pred, y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ET accuracy 0.895\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier()\n",
    "et.fit(X_train, y_train)\n",
    "y_pred = et.predict(X_validation)\n",
    "print('ET accuracy {}'.format(accuracy_score(y_pred, y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Ensemble accuracy 0.924\n",
      "Soft Ensemble accuracy 0.951\n"
     ]
    }
   ],
   "source": [
    "estimators = [('svm',svm_pipe), ('rf',rf), ('et',et)]\n",
    "hard_ensemble = VotingClassifier(estimators, voting='hard')\n",
    "hard_ensemble.fit(X_train, y_train)\n",
    "y_pred = hard_ensemble.predict(X_validation)\n",
    "print('Hard Ensemble accuracy {}'.format(accuracy_score(y_pred, y_validation)))\n",
    "\n",
    "soft_ensemble = VotingClassifier(estimators, voting='soft')\n",
    "soft_ensemble.fit(X_train, y_train)\n",
    "y_pred = soft_ensemble.predict(X_validation)\n",
    "print('Soft Ensemble accuracy {}'.format(accuracy_score(y_pred, y_validation)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate in Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy 0.899\n",
      "RF accuracy 0.882\n",
      "ET accuracy 0.889\n",
      "HARD accuracy 0.908\n",
      "SOFT accuracy 0.917\n"
     ]
    }
   ],
   "source": [
    "estimators = [('svm',svm_pipe), ('rf',rf), ('et',et),('hard', hard_ensemble),('soft', soft_ensemble)]\n",
    "for e in estimators:\n",
    "    y_pred = e[1].predict(X_test)\n",
    "    print('{} accuracy {}'.format(e[0].upper(),accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " - First train models using train_data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = [('svm',svm_pipe), ('rf',rf), ('et',et)]\n",
    "pred_validation = []\n",
    "pred_test = []\n",
    "for e in estimators:\n",
    "    pred_validation.append(e[1].predict(X_validation))\n",
    "    pred_test.append(e[1].predict(X_test))\n",
    "    \n",
    "pred_validation = np.array(pred_validation).T\n",
    "pred_test = np.array(pred_test).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train Meta\n",
    "meta = RandomForestClassifier()\n",
    "meta.fit(pred_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta accuracy 0.88\n"
     ]
    }
   ],
   "source": [
    "y_pred = meta.predict(pred_test)\n",
    "print('Meta accuracy {}'.format(accuracy_score(y_pred, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
